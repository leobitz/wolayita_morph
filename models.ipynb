{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM, TimeDistributed\n",
    "from keras.layers import Concatenate, Flatten\n",
    "from keras.layers import GRU, Conv2D, MaxPooling2D\n",
    "from keras.layers import Input, Reshape\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import RMSprop\n",
    "# from keras.utils.vis_utils import plot_model\n",
    "import keras\n",
    "\n",
    "# returns train, inference_encoder and inference_decoder models\n",
    "def define_models(n_input, n_output, n_units, n_feature):\n",
    "    # define training encoder\n",
    "    encoder_inputs = Input(shape=(None, n_input), name=\"root_word_input\")\n",
    "    encoder = LSTM(n_units, return_state=True)\n",
    "    encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "    encoder_states = [state_h, state_c]\n",
    "    print(state_h.shape)\n",
    "    # define training decoder\n",
    "    decoder_inputs = Input(shape=(None, n_output), name=\"target_word_input\")\n",
    "    \n",
    "    decoder_lstm = LSTM(n_units, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "    \n",
    "    feature_input = Input(shape=(None, n_feature), name=\"word_feature_input\")\n",
    "    feat_out = Dense(10, activation=\"relu\", name=\"feature_output\")(feature_input)\n",
    "    print(feat_out.shape)\n",
    "    x = Concatenate(name=\"feature_merge\")([decoder_outputs, feat_out])\n",
    "    decoder_dense = Dense(n_output, activation='softmax', name=\"train_output\")\n",
    "    decoder_outputs = decoder_dense(x)\n",
    "    \n",
    "    model = Model([encoder_inputs, decoder_inputs, feature_input], decoder_outputs)\n",
    "#     define inference encoder\n",
    "    encoder_model = Model(encoder_inputs, encoder_states)\n",
    "    # define inference decoder\n",
    "    decoder_state_input_h = Input(shape=(n_units,))\n",
    "    decoder_state_input_c = Input(shape=(n_units,))\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    \n",
    "    word_feature_input = Input(shape=(None, n_feature), name=\"word_feature_input\")\n",
    "    word_feat_out = Dense(10, activation=\"relu\")(word_feature_input)\n",
    "    word_out = Concatenate()([decoder_outputs, word_feat_out])\n",
    "    \n",
    "    decoder_outputs = decoder_dense(word_out)\n",
    "    decoder_model = Model([decoder_inputs] + decoder_states_inputs + [word_feature_input] , [decoder_outputs] + decoder_states)\n",
    "\n",
    "    return model, encoder_model, decoder_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq(n_input, n_output, n_units, n_feature):\n",
    "    # define training encoder\n",
    "    feat_units = 15\n",
    "    encoder_inputs = Input(shape=(None, n_input), name=\"root_word_input\")\n",
    "    encoder = LSTM(n_units, return_state=True)\n",
    "    encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "    \n",
    "    feature_input = Input(shape=(n_feature,), name=\"word_feature_input\")\n",
    "    feat_out = Dense(feat_units, activation=\"relu\", name=\"feature_output\")(feature_input)\n",
    "    x = Concatenate()([state_h, feat_out])\n",
    "    x2 = Concatenate()([state_c, feat_out])\n",
    "    state_h = Dense(n_units, activation='relu')(x)\n",
    "    state_c = Dense(n_units, activation='relu')(x2)\n",
    "    encoder_states = [state_h, state_c]\n",
    "    \n",
    "    decoder_inputs = Input(shape=(None, n_output), name=\"target_word_input\")\n",
    "    decoder_lstm = LSTM(n_units, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "#     decoder_outputs, _, _ = decoder_lstm(decoder_inputs)\n",
    "    decoder_dense = Dense(n_output, activation='softmax', name=\"train_output\")\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    model = Model([encoder_inputs, decoder_inputs, feature_input], decoder_outputs)\n",
    "#     define inference encoder\n",
    "    encoder_model = Model([encoder_inputs, feature_input], encoder_states)\n",
    "    # define inference decoder\n",
    "    decoder_state_input_h = Input(shape=(n_units,))\n",
    "    decoder_state_input_c = Input(shape=(n_units,))\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "\n",
    "    return model, encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2(n_input, n_output, n_feature, n_enc_units, n_dec_units):\n",
    "    # define training encoder\n",
    "    feat_units = 15\n",
    "    encoder_inputs = Input(shape=(None, n_input), name=\"root_word_input\")\n",
    "    encoder = LSTM(n_enc_units, return_state=True, name=\"encoder_lstm\")\n",
    "    encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "    \n",
    "    feature_input = Input(shape=(n_feature,), name=\"word_feature_input\")\n",
    "    feat_out = Dense(feat_units, activation=\"relu\", name=\"feature_output\")(feature_input)\n",
    "    x = Concatenate()([state_h, feat_out])\n",
    "    x2 = Concatenate()([state_c, feat_out])\n",
    "    state_h = Dense(n_dec_units, activation='sigmoid')(x)\n",
    "    state_c = Dense(n_dec_units, activation='sigmoid')(x2)\n",
    "    encoder_states = [state_h, state_c]\n",
    "    \n",
    "    decoder_inputs = Input(shape=(None, n_output), name=\"target_word_input\")\n",
    "    decoder_lstm = LSTM(n_dec_units, return_sequences=True, return_state=True, name=\"decoder_lstm\")\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "    decoder_dense = Dense(n_output, activation='softmax', name=\"train_output\")\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    model = Model([encoder_inputs, decoder_inputs, feature_input], decoder_outputs)\n",
    "\n",
    "    encoder_model = Model([encoder_inputs, feature_input], encoder_states)\n",
    "    # define inference decoder\n",
    "    decoder_state_input_h = Input(shape=(n_dec_units,))\n",
    "    decoder_state_input_c = Input(shape=(n_dec_units,))\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "\n",
    "    return model, encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, infenc, infdec = seq2(27, 27, 29, 64,128)\n",
    "# train.summary()\n",
    "# train.input[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_model(n_input, n_output, n_feature, n_enc_units, n_dec_units, feat_units = 10):\n",
    "    root_word_input = Input(shape=(15, 28, 1), name=\"root_word_input\")\n",
    "    feature_input = Input(shape=(n_feature,), name=\"word_feature_input\")\n",
    "    \n",
    "    x = Conv2D(16, (3, 3), padding='same', activation='relu')(root_word_input)\n",
    "    feat_out = Dense(feat_units, activation=\"relu\", name=\"feature_output\")(feature_input)\n",
    "    x = MaxPooling2D(2, 2)(x)\n",
    "    flat_output = Flatten()(x)\n",
    "    x = Dense(100, activation='relu')(flat_output)\n",
    "    x = Dropout(.4)(x)\n",
    "    x = Concatenate()([x, feat_out])\n",
    "#     state_h = Dense(n_dec_units, activation='relu')(x)\n",
    "    state_h = Dense(n_dec_units, activation='relu')(x)\n",
    "    state_h = Dropout(.4)(state_h)\n",
    "    decoder_inputs = Input(shape=(None, n_output), name=\"target_word_input\")\n",
    "    decoder_gru = GRU(n_dec_units, return_sequences=True, return_state=True, name=\"decoder_gru\")\n",
    "    decoder_outputs, _= decoder_gru(decoder_inputs, initial_state=state_h)\n",
    "    \n",
    "    decoder_dense = Dense(n_output, activation='softmax', name=\"train_output\")\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    model = Model([root_word_input, decoder_inputs, feature_input], decoder_outputs)\n",
    "    encoder_model = Model([root_word_input, feature_input], state_h)\n",
    "    \n",
    "    decoder_state_input_h = Input(shape=(n_dec_units,))\n",
    "    decoder_outputs, state_h= decoder_gru(decoder_inputs, initial_state=decoder_state_input_h)\n",
    "\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model([decoder_inputs, decoder_state_input_h], [decoder_outputs, state_h])\n",
    "\n",
    "    return model, encoder_model, decoder_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "root_word_input (InputLayer)    (None, 15, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 15, 28, 16)   160         root_word_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 7, 14, 16)    0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 1568)         0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "word_feature_input (InputLayer) (None, 29)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          156900      flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "feature_output (Dense)          (None, 10)           300         word_feature_input[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 110)          0           dense_2[0][0]                    \n",
      "                                                                 feature_output[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "target_word_input (InputLayer)  (None, None, 27)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          14208       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (GRU)              [(None, None, 128),  59904       target_word_input[0][0]          \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "train_output (Dense)            (None, None, 27)     3483        decoder_lstm[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 234,955\n",
      "Trainable params: 234,955\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "train, infenc, infdec = conv_model(27, 27, 29, 64,128)\n",
    "train.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(infenc, infdec, source, feat, n_steps, cardinality):\n",
    "    # encode\n",
    "    state = infenc.predict([source, feat])\n",
    "    # start of sequence input\n",
    "    start = [0.0 for _ in range(cardinality)]\n",
    "#     start[0] = 1\n",
    "    target_seq = np.array(start).reshape(1, 1, cardinality)\n",
    "    # collect predictions\n",
    "    output = list()\n",
    "    for t in range(n_steps):\n",
    "        # predict next char\n",
    "        yhat, h, c = infdec.predict([target_seq] + state)\n",
    "        # store prediction\n",
    "        output.append(yhat[0,0,:])\n",
    "        # update state\n",
    "        state = [h, c]\n",
    "        # update target sequence\n",
    "        target_seq = yhat\n",
    "    return np.array(output)\n",
    "\n",
    "def predict2(infenc, infdec, source, feat, n_steps, cardinality):\n",
    "    # encode\n",
    "    state = infenc.predict([source, feat])\n",
    "    # start of sequence input\n",
    "    start = [0.0 for _ in range(cardinality)]\n",
    "#     start[0] = 1\n",
    "    target_seq = np.array(start).reshape(1, 1, cardinality)\n",
    "    # collect predictions\n",
    "    output = list()\n",
    "    for t in range(n_steps):\n",
    "        # predict next char\n",
    "        yhat, h= infdec.predict([target_seq, state])\n",
    "        # store prediction\n",
    "        output.append(yhat[0,0,:])\n",
    "        # update state\n",
    "        state = h\n",
    "        # update target sequence\n",
    "        target_seq = yhat\n",
    "    return np.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
