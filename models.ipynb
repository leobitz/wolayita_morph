{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\leo\\appdata\\local\\conda\\conda\\envs\\gpu-tf\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM, TimeDistributed\n",
    "from keras.layers import Concatenate, Flatten\n",
    "from keras.layers import GRU, Conv2D, MaxPooling2D\n",
    "from keras.layers import Input, Reshape\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import RMSprop\n",
    "# from keras.utils.vis_utils import plot_model\n",
    "import keras\n",
    "\n",
    "# returns train, inference_encoder and inference_decoder models\n",
    "def define_models(n_input, n_output, n_units, n_feature):\n",
    "    # define training encoder\n",
    "    encoder_inputs = Input(shape=(None, n_input), name=\"root_word_input\")\n",
    "    encoder = LSTM(n_units, return_state=True)\n",
    "    encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "    encoder_states = [state_h, state_c]\n",
    "    print(state_h.shape)\n",
    "    # define training decoder\n",
    "    decoder_inputs = Input(shape=(None, n_output), name=\"target_word_input\")\n",
    "    \n",
    "    decoder_lstm = LSTM(n_units, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "    \n",
    "    feature_input = Input(shape=(None, n_feature), name=\"word_feature_input\")\n",
    "    feat_out = Dense(10, activation=\"relu\", name=\"feature_output\")(feature_input)\n",
    "    print(feat_out.shape)\n",
    "    x = Concatenate(name=\"feature_merge\")([decoder_outputs, feat_out])\n",
    "    decoder_dense = Dense(n_output, activation='softmax', name=\"train_output\")\n",
    "    decoder_outputs = decoder_dense(x)\n",
    "    \n",
    "    model = Model([encoder_inputs, decoder_inputs, feature_input], decoder_outputs)\n",
    "#     define inference encoder\n",
    "    encoder_model = Model(encoder_inputs, encoder_states)\n",
    "    # define inference decoder\n",
    "    decoder_state_input_h = Input(shape=(n_units,))\n",
    "    decoder_state_input_c = Input(shape=(n_units,))\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    \n",
    "    word_feature_input = Input(shape=(None, n_feature), name=\"word_feature_input\")\n",
    "    word_feat_out = Dense(10, activation=\"relu\")(word_feature_input)\n",
    "    word_out = Concatenate()([decoder_outputs, word_feat_out])\n",
    "    \n",
    "    decoder_outputs = decoder_dense(word_out)\n",
    "    decoder_model = Model([decoder_inputs] + decoder_states_inputs + [word_feature_input] , [decoder_outputs] + decoder_states)\n",
    "\n",
    "    return model, encoder_model, decoder_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq(n_input, n_output, n_units, n_feature):\n",
    "    # define training encoder\n",
    "    feat_units = 15\n",
    "    encoder_inputs = Input(shape=(None, n_input), name=\"root_word_input\")\n",
    "    encoder = LSTM(n_units, return_state=True)\n",
    "    encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "    \n",
    "    feature_input = Input(shape=(n_feature,), name=\"word_feature_input\")\n",
    "    feat_out = Dense(feat_units, activation=\"relu\", name=\"feature_output\")(feature_input)\n",
    "    x = Concatenate()([state_h, feat_out])\n",
    "    x2 = Concatenate()([state_c, feat_out])\n",
    "    state_h = Dense(n_units, activation='relu')(x)\n",
    "    state_c = Dense(n_units, activation='relu')(x2)\n",
    "    encoder_states = [state_h, state_c]\n",
    "    \n",
    "    decoder_inputs = Input(shape=(None, n_output), name=\"target_word_input\")\n",
    "    decoder_lstm = LSTM(n_units, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "#     decoder_outputs, _, _ = decoder_lstm(decoder_inputs)\n",
    "    decoder_dense = Dense(n_output, activation='softmax', name=\"train_output\")\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    model = Model([encoder_inputs, decoder_inputs, feature_input], decoder_outputs)\n",
    "#     define inference encoder\n",
    "    encoder_model = Model([encoder_inputs, feature_input], encoder_states)\n",
    "    # define inference decoder\n",
    "    decoder_state_input_h = Input(shape=(n_units,))\n",
    "    decoder_state_input_c = Input(shape=(n_units,))\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "\n",
    "    return model, encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2(n_input, n_output, n_feature, n_enc_units, n_dec_units):\n",
    "    # define training encoder\n",
    "    feat_units = 15\n",
    "    encoder_inputs = Input(shape=(None, n_input), name=\"root_word_input\")\n",
    "    encoder = LSTM(n_enc_units, return_state=True, name=\"encoder_lstm\")\n",
    "    encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "    \n",
    "    feature_input = Input(shape=(n_feature,), name=\"word_feature_input\")\n",
    "    feat_out = Dense(feat_units, activation=\"relu\", name=\"feature_output\")(feature_input)\n",
    "    x = Concatenate()([state_h, feat_out])\n",
    "    x2 = Concatenate()([state_c, feat_out])\n",
    "    state_h = Dense(n_dec_units, activation='sigmoid')(x)\n",
    "    state_c = Dense(n_dec_units, activation='sigmoid')(x2)\n",
    "    encoder_states = [state_h, state_c]\n",
    "    \n",
    "    decoder_inputs = Input(shape=(None, n_output), name=\"target_word_input\")\n",
    "    decoder_lstm = LSTM(n_dec_units, return_sequences=True, return_state=True, name=\"decoder_lstm\")\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "    decoder_dense = Dense(n_output, activation='softmax', name=\"train_output\")\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    model = Model([encoder_inputs, decoder_inputs, feature_input], decoder_outputs)\n",
    "\n",
    "    encoder_model = Model([encoder_inputs, feature_input], encoder_states)\n",
    "    # define inference decoder\n",
    "    decoder_state_input_h = Input(shape=(n_dec_units,))\n",
    "    decoder_state_input_c = Input(shape=(n_dec_units,))\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "\n",
    "    return model, encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_model(n_input, n_output, n_feature, n_enc_units, n_dec_units, feat_units = 10):\n",
    "    root_word_input = Input(shape=(15, 28, 1), name=\"root_word_input\")\n",
    "    feature_input = Input(shape=(n_feature,), name=\"word_feature_input\")\n",
    "    feat_out = Dense(feat_units, activation=\"relu\", name=\"feature_output\")(feature_input)\n",
    "    \n",
    "    x = Conv2D(16, (3, 3), padding='same', activation='relu')(root_word_input)\n",
    "    x = MaxPooling2D(2, 2)(x)\n",
    "    x = Conv2D(8, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(2, 2)(x)\n",
    "    \n",
    "    flat_output = Flatten()(x)\n",
    "    x = Concatenate()([flat_output, feat_out])\n",
    "#     x = Dense(n_dec_units * 2, activation='relu')(flat_output)\n",
    "    \n",
    "    state_h = Dense(n_dec_units, activation='relu')(x)\n",
    "    \n",
    "    decoder_inputs = Input(shape=(None, n_output), name=\"target_word_input\")\n",
    "    decoder_gru = GRU(n_dec_units, return_sequences=True, return_state=True, name=\"decoder_gru\")\n",
    "    decoder_outputs, _= decoder_gru(decoder_inputs, initial_state=state_h)\n",
    "    \n",
    "    decoder_dense = Dense(n_output, activation='softmax', name=\"train_output\")\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    model = Model([root_word_input, decoder_inputs, feature_input], decoder_outputs)\n",
    "    encoder_model = Model([root_word_input, feature_input], state_h)\n",
    "    \n",
    "    decoder_state_input_h = Input(shape=(n_dec_units,))\n",
    "    decoder_outputs, state_h= decoder_gru(decoder_inputs, initial_state=decoder_state_input_h)\n",
    "\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model([decoder_inputs, decoder_state_input_h], [decoder_outputs, state_h])\n",
    "\n",
    "    return model, encoder_model, decoder_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_model2(n_input, n_output, n_feature, n_enc_units, n_dec_units, feat_units = 10):\n",
    "    root_word_input = Input(shape=(15, 28, 1), name=\"root_word_input\")\n",
    "    feature_input = Input(shape=(n_feature,), name=\"word_feature_input\")\n",
    "    \n",
    "    x = Conv2D(16, (3, 3), padding='same', activation='relu')(root_word_input)\n",
    "    feat_out = Dense(feat_units, activation=\"relu\", name=\"feature_output\")(feature_input)\n",
    "    x = MaxPooling2D(2, 2)(x)\n",
    "    flat_output = Flatten()(x)\n",
    "#     x = Dense(100, activation='relu')(flat_output)\n",
    "    x = Dense(n_dec_units - feat_units, activation='relu')(flat_output)\n",
    "#     state_h = Dropout(.4)(state_h)\n",
    "    \n",
    "    state_h = Concatenate()([x, feat_out])\n",
    "    decoder_inputs = Input(shape=(None, n_output), name=\"target_word_input\")\n",
    "    decoder_gru = GRU(n_dec_units, return_sequences=True, return_state=True, name=\"decoder_gru\")\n",
    "    decoder_outputs, _= decoder_gru(decoder_inputs, initial_state=state_h)\n",
    "    \n",
    "    decoder_dense = Dense(n_output, activation='softmax', name=\"train_output\")\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    model = Model([root_word_input, decoder_inputs, feature_input], decoder_outputs)\n",
    "    encoder_model = Model([root_word_input, feature_input], state_h)\n",
    "    \n",
    "    decoder_state_input_h = Input(shape=(n_dec_units,))\n",
    "    decoder_outputs, state_h= decoder_gru(decoder_inputs, initial_state=decoder_state_input_h)\n",
    "\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model([decoder_inputs, decoder_state_input_h], [decoder_outputs, state_h])\n",
    "\n",
    "    return model, encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_model3(n_input, n_output, n_feature, n_enc_units, n_dec_units, feat_units = 10):\n",
    "    root_word_input = Input(shape=(15, 28, 1), name=\"root_word_input\")\n",
    "    feature_input = Input(shape=(n_feature,), name=\"word_feature_input\")\n",
    "    \n",
    "    x = Conv2D(16, (3, 3), padding='same', activation='relu')(root_word_input)\n",
    "    feat_out = Dense(feat_units, activation=\"relu\", name=\"feature_output\")(feature_input)\n",
    "    x = MaxPooling2D(2, 2)(x)\n",
    "    flat_output = Flatten()(x)\n",
    "#     x = Dense(100, activation='relu')(flat_output)\n",
    "    x = Dense(n_dec_units - feat_units, activation='relu')(flat_output)\n",
    "#     state_h = Dropout(.4)(state_h)\n",
    "    \n",
    "    state_h = Concatenate()([x, feat_out])\n",
    "    decoder_inputs = Input(shape=(None, n_output), name=\"target_word_input\")\n",
    "    x_decode, _ = GRU(n_dec_units, initial_state=state_h, return_sequences=True, return_state=True, name=\"decoder_gru_1\")(decoder_inputs)\n",
    "    decoder_gru = GRU(n_dec_units, return_sequences=True, return_state=True, name=\"decoder_gru\")\n",
    "    decoder_outputs, _= decoder_gru(x_decode, initial_state=state_h)\n",
    "    \n",
    "    decoder_dense = Dense(n_output, activation='softmax', name=\"train_output\")\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    model = Model([root_word_input, decoder_inputs, feature_input], decoder_outputs)\n",
    "    encoder_model = Model([root_word_input, feature_input], state_h)\n",
    "    \n",
    "    decoder_state_input_h = Input(shape=(n_dec_units,))\n",
    "    x_decode = GRU(n_dec_units, initial_state=decoder_state_input_h, name=\"decoder_gru_1\")(decoder_inputs)\n",
    "    decoder_outputs, state_h= decoder_gru(x_decode, initial_state=decoder_state_input_h)\n",
    "    decoder_outputs, state_h= decoder_gru(decoder_inputs, initial_state=decoder_state_input_h)\n",
    "\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model([decoder_inputs, decoder_state_input_h], [decoder_outputs, state_h])\n",
    "\n",
    "    return model, encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "root_word_input (InputLayer)    (None, 15, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 15, 28, 16)   160         root_word_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 7, 14, 16)    0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 1568)         0           max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "word_feature_input (InputLayer) (None, 29)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 54)           84726       flatten_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "feature_output (Dense)          (None, 10)           300         word_feature_input[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "target_word_input (InputLayer)  (None, None, 27)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 64)           0           dense_17[0][0]                   \n",
      "                                                                 feature_output[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gru (GRU)               [(None, None, 64), ( 17664       target_word_input[0][0]          \n",
      "                                                                 concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "train_output (Dense)            (None, None, 27)     1755        decoder_gru[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 104,605\n",
      "Trainable params: 104,605\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "train, infenc, infdec = conv_model(27, 27, 29, 64,64)\n",
    "train.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(infenc, infdec, source, feat, n_steps, cardinality):\n",
    "    # encode\n",
    "    state = infenc.predict([source, feat])\n",
    "    # start of sequence input\n",
    "    start = [0.0 for _ in range(cardinality)]\n",
    "#     start[0] = 1\n",
    "    target_seq = np.array(start).reshape(1, 1, cardinality)\n",
    "    # collect predictions\n",
    "    output = list()\n",
    "    for t in range(n_steps):\n",
    "        # predict next char\n",
    "        yhat, h, c = infdec.predict([target_seq] + state)\n",
    "        # store prediction\n",
    "        output.append(yhat[0,0,:])\n",
    "        # update state\n",
    "        state = [h, c]\n",
    "        # update target sequence\n",
    "        target_seq = yhat\n",
    "    return np.array(output)\n",
    "\n",
    "def predict2(infenc, infdec, source, feat, n_steps, cardinality):\n",
    "    # encode\n",
    "    state = infenc.predict([source, feat])\n",
    "    # start of sequence input\n",
    "    start = [0.0 for _ in range(cardinality)]\n",
    "#     start[0] = 1\n",
    "    target_seq = np.array(start).reshape(1, 1, cardinality)\n",
    "    # collect predictions\n",
    "    output = list()\n",
    "    for t in range(n_steps):\n",
    "        # predict next char\n",
    "        yhat, h= infdec.predict([target_seq, state])\n",
    "        # store prediction\n",
    "        output.append(yhat[0,0,:])\n",
    "        # update state\n",
    "        state = h\n",
    "        # update target sequence\n",
    "        target_seq = yhat\n",
    "    return np.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
