{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amany\\appdata\\local\\conda\\conda\\envs\\gputf3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "%run data_gen.ipynb\n",
    "%run models.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = DataGen()\n",
    "\n",
    "n_features = len(char2int)\n",
    "n_steps_in = dg.max_root_len\n",
    "n_steps_out = dg.max_output_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "n_batches = int(len(dg.words) * .7 / batch_size) \n",
    "gen = dg.gen2(batch_size=batch_size, n_batches=n_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\amany\\appdata\\local\\conda\\conda\\envs\\gputf3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "# define model \n",
    "# train, infenc, infdec = seq2(n_features, n_features, 64, dg.word_feat_len)\n",
    "train, infenc, infdec = conv_model2(n_features, n_features, dg.word_feat_len, 64, 64)\n",
    "train.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "tensorboard = TensorBoard(log_dir='logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5702/5702 [==============================] - 206s 36ms/step - loss: 0.1715 - acc: 0.9468\n",
      "Epoch 2/5\n",
      "5702/5702 [==============================] - 207s 36ms/step - loss: 0.0224 - acc: 0.9911\n",
      "Epoch 3/5\n",
      "5702/5702 [==============================] - 205s 36ms/step - loss: 0.0146 - acc: 0.9929\n",
      "Epoch 4/5\n",
      "5702/5702 [==============================] - 205s 36ms/step - loss: 0.0119 - acc: 0.9935\n",
      "Epoch 5/5\n",
      "5702/5702 [==============================] - 205s 36ms/step - loss: 0.0109 - acc: 0.9937\n"
     ]
    }
   ],
   "source": [
    "history = train.fit_generator(gen, steps_per_epoch=n_batches, epochs = 5, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_n_batches, test_batch_size = 30, 100 \n",
    "test_gen = dg.gen2(batch_size=test_batch_size, n_batches=test_n_batches, trainset=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 matay           matayiyogaa                   matayiyogaanaageetaariidaanii\n",
      "1 sal             salissiyaro                   salissiyarooroaauuu          \n",
      "2 maaret          maaretaro                     maaretidaroogaanaarariiiaaana\n",
      "3 yedd            yeddaanaagoo                  yeddaanaagooaaaaaaaanaanaanaa\n",
      "4 cagg            cagissidori                   cagissidoriisaanii           \n",
      "5 achch           achchissiyonaa                achchissiyonaaseetaakiissauuu\n",
      "6 homppat         homppatiyonii                 homppatiyoniidanaadiikaariiaa\n",
      "7 paall           paallogeetoo                  paallogeetoogaanaarooiiiaaari\n",
      "8 baxx            baxissennee                   baxissenneetaaniiksanuukkaadi\n",
      "9 warqqall        warqqalliis                   warqqalliissuanaadaasuuuuukku\n",
      "10 daadir          daadira                       daadiraysuatuutuutuukuuuuuuuu\n",
      "11 paatt           paatissibeokkonaa             paatissibeokkonaasiiisaakuukk\n",
      "12 qoom            qoomekkee                     qoomekkeesaana               \n",
      "13 een             eenawsu                       eenawsuuuuuuuuuuuuuuuuuuuuuuu\n",
      "14 leebbaashet     leebbaashetiyogee             leebbaaseetiyogeetaariiiaaroo\n",
      "15 gombb           gombbokkona                   gombbokkonaasiiksaaaaauukkuu \n",
      "16 konkkom         konkkomiyogaa                 konkkomiyogaanaageetaanaarana\n",
      "17 kobay           kobayiyagee                   kobayiyageetaariiiaanaariiauu\n",
      "18 kanddot         kanddotiyori                  kanddotiyoriiaanaaraetaatuu  \n",
      "19 cuul            cuuladee                      cuuladeetaamiidasaakuuukuu   \n",
      "20 hayzz           hayzzi                        hayzzidetiideaariikaariisaasu\n",
      "21 tafitaf         tafitafidanaa                 tafitafidanaadiiddiiddiidauuu\n",
      "22 wocam           wocamada                      wocamadaanadiiddiiddiidaissaa\n",
      "23 xurumbb         xurumbissona                  xurumbissonaadiissaauut      \n",
      "24 makkis          makkisissiyagaa               makkisissiyagaagoogoanaaaaaro\n",
      "25 xal             xalidageetee                  xalidageeteeteekkeeiidadaiisa\n",
      "26 hekkul''        hekkul''eeta                  hekkul''eetabeekkaiisaauuukku\n",
      "27 mugg            mugissana                     mugissanaidaasuu             \n",
      "28 cingg           cinggori                      cinggirariiiiiiiiiiiaaaaari  \n",
      "29 sham            shamoro                       shamidorooaaariiaauariiyaaan \n",
      "Word Similarity Average: 0.47%\n",
      "Accuracy: 0.00%\n",
      "Accuracy: 77.27%\n"
     ]
    }
   ],
   "source": [
    "total, correct = 0, 0\n",
    "in_word = 0\n",
    "sims = []\n",
    "for b in range(test_n_batches):\n",
    "    [X1, X2, X3], y = next(test_gen)\n",
    "    for j in range(test_batch_size):\n",
    "        X33 = X3[j].reshape((1, X3.shape[1])) \n",
    "        X11 = X1[j].reshape((1, X1.shape[1], X1.shape[2], 1))\n",
    "        target = predict2(infenc, infdec, X11, X33, n_steps_out, n_features)\n",
    "        root = ''.join(dg.one_hot_decode(X1[j])).replace('&', ' ')\n",
    "        word = ''.join(dg.one_hot_decode(y[j])).replace('&', ' ')\n",
    "        targetS = ''.join(dg.one_hot_decode(target)).replace('&', ' ')\n",
    "        sims.append(dg.word_sim(word, targetS))\n",
    "        if dg.one_hot_decode(y[j]) == dg.one_hot_decode(target):\n",
    "            correct += 1\n",
    "        if root.strip() in targetS.strip():\n",
    "            in_word += 1\n",
    "    print(b, root, word, targetS)\n",
    "    total += test_batch_size\n",
    "    \n",
    "word_sim_average = sum(sims)/len(sims)\n",
    "print('Word Similarity Average: {0:.2f}%'.format(word_sim_average))\n",
    "print('Accuracy: %.2f%%' % (float(correct)/float(total)*100.0))\n",
    "print('Accuracy: %.2f%%' % (float(in_word)/float(total)*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
