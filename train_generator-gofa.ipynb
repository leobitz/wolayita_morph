{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "%run data_gen.ipynb\n",
    "%run models.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = DataGen(data=\"data_shuffled.txt\")\n",
    "\n",
    "n_features = len(char2int)\n",
    "n_steps_in = dg.max_root_len\n",
    "n_steps_out = dg.max_output_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "729859.2\n"
     ]
    }
   ],
   "source": [
    "print(len(dg.words) * .7)\n",
    "batch_size = 128\n",
    "n_batches = int(len(dg.words) * .7 / batch_size) \n",
    "gen = dg.gen2(batch_size=batch_size, n_batches=n_batches)\n",
    "# [x1, x2, x3], y = next(gen)\n",
    "# print(x1.shape, x2.shape, x3.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model \n",
    "# train, infenc, infdec = seq2(n_features, n_features, 64, dg.word_feat_len)\n",
    "train, infenc, infdec = conv_model(n_features, n_features, dg.word_feat_len, 64, 128)\n",
    "train.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "# tensorboard = TensorBoard(log_dir='logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "root_word_input (InputLayer)    (None, 15, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 15, 28, 20)   520         root_word_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 5, 9, 20)     0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 900)          0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "word_feature_input (InputLayer) (None, 32)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 118)          106318      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "feature_output (Dense)          (None, 10)           330         word_feature_input[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "target_word_input (InputLayer)  (None, None, 28)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128)          0           dense_1[0][0]                    \n",
      "                                                                 feature_output[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gru (GRU)               [(None, None, 128),  60288       target_word_input[0][0]          \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "train_output (Dense)            (None, None, 28)     3612        decoder_gru[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 171,068\n",
      "Trainable params: 171,068\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "train.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "5702/5702 [==============================] - 227s 40ms/step - loss: 0.1366\n",
      "Epoch 2/2\n",
      "5702/5702 [==============================] - 215s 38ms/step - loss: 0.0147\n"
     ]
    }
   ],
   "source": [
    "history = train.fit_generator(gen, steps_per_epoch=n_batches, epochs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_n_batches, test_batch_size = 30, 100 \n",
    "test_gen = dg.gen2(batch_size=test_batch_size, n_batches=test_n_batches, trainset=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 matay           matayiyogaa&                    matayiyogaa&                   \n",
      "1 sal             salissiyaro&                    salissiyaro&                   \n",
      "2 maaret          maaretaro&                      maaretidaro&                   \n",
      "3 yedd            yeddaanaagoo&                   yeddaanaagoo&                  \n",
      "4 cagg            cagissidori&                    cagissidori&                   \n",
      "5 achch           achchissiyonaa&                 achchissiyonaa&                \n",
      "6 homppat         homppatiyonii&                  homppatiyon                    \n",
      "7 paall           paallogeetoo&                   paalligeetoo&                  \n",
      "8 baxx            baxissennee&                    baxissennee&                   \n",
      "9 warqqall        warqqalliis&                    warqqalliis&                   \n",
      "10 daadir          daadira&                        daadira&                       \n",
      "11 paatt           paatissibeokkonaa&              paatissibeokkonaa&             \n",
      "12 qoom            qoomekkee&                      qoomekkee&                     \n",
      "13 een             eenawsu&                        eenawsu&                       \n",
      "14 leebbaashet     leebbaashetiyogee&              leebbaashettiyogee&            \n",
      "15 gombb           gombbokkona&                    gombbokkona&                   \n",
      "16 konkkom         konkkomiyogaa&                  konkkomiyogaa&                 \n",
      "17 kobay           kobayiyagee&                    kobayiyagee&                   \n",
      "18 kanddot         kanddotiyori&                   kanddotiyori&                  \n",
      "19 cuul            cuuladee&                       cuuladee&                      \n",
      "20 hayzz           hayzzi&                         hayzzi&                        \n",
      "21 tafitaf         tafitafidanaa&                  tafitafidanaa&                 \n",
      "22 wocam           wocamada&                       wocamada&                      \n",
      "23 xurumbb         xurumbissona&                   xurumbissona&                  \n",
      "24 makkis          makkisissiyagaa&                makkisissiyagaa&               \n",
      "25 xal             xalidageetee&                   xalidogeetee&                  \n",
      "26 hekkul''        hekkul''eeta&                   hekkul''eeta&                  \n",
      "27 mugg            mugissana&                      mugissana&                     \n",
      "28 cingg           cinggori&                       cinggori&                      \n",
      "29 sham            shamoro&                        shamodoro&                     \n",
      "Word Similarity Average: 0.95%\n",
      "Exact Accuracy: 69.77%\n",
      "Word in Accuracy: 76.67%\n"
     ]
    }
   ],
   "source": [
    "total, correct = 0, 0\n",
    "in_word = 0\n",
    "sims = []\n",
    "for b in range(test_n_batches):\n",
    "    [X1, X2, X3], y = next(test_gen)\n",
    "    for j in range(test_batch_size):\n",
    "        X33 = X3[j].reshape((1, X3.shape[1])) \n",
    "        X11 = X1[j].reshape((1, X1.shape[1], X1.shape[2], 1))\n",
    "        target = predict2(infenc, infdec, X11, X33, n_steps_out, n_features)\n",
    "        root = ''.join(dg.one_hot_decode(X1[j]))#.replace('&', ' ')\n",
    "        word = ''.join(dg.one_hot_decode(y[j]))#.replace('&', ' ')\n",
    "        targetS = ''.join(dg.one_hot_decode(target))#.replace('&', ' ')\n",
    "        sims.append(dg.word_sim(word, targetS))\n",
    "        if dg.one_hot_decode(y[j]) == dg.one_hot_decode(target):\n",
    "            correct += 1\n",
    "        if root.strip() in targetS.strip():\n",
    "            in_word += 1\n",
    "    print(b, root, word, targetS)\n",
    "    total += test_batch_size\n",
    "    \n",
    "word_sim_average = sum(sims)/len(sims)\n",
    "print('Word Similarity Average: {0:.2f}%'.format(word_sim_average))\n",
    "print('Exact Accuracy: %.2f%%' % (float(correct)/float(total)*100.0))\n",
    "print('Word in Accuracy: %.2f%%' % (float(in_word)/float(total)*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg2 = DataGen(data=\"final.txt\")\n",
    "\n",
    "n_features = len(char2int)\n",
    "n_steps_in = dg2.max_root_len\n",
    "n_steps_out = dg2.max_output_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "924.6999999999999\n"
     ]
    }
   ],
   "source": [
    "print(len(dg2.words) * .7)\n",
    "batch_size = 50\n",
    "n_batches = int(len(dg2.words) * .7 / batch_size) \n",
    "gen2 = dg2.gen2(batch_size=batch_size, n_batches=n_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 saaphoy         saaphoyis&        saaphoyiis&      \n",
      "1 shinqq          shinqqis&         shinqqiis&       \n",
      "2 soor            sooris&           sooriis&         \n",
      "3 toppay          toppayis&         toppayiis&       \n",
      "4 wolqqantt       wolqqanttis&      wolqqanttiis&    \n",
      "5 xayss           xayssis&          xayssiis&        \n",
      "6 yarkk           yarkkis&          yarkkiis&        \n",
      "7 zaway           zawayis&          zawayiis&        \n",
      "8 saaphoy         saaphoyis&        saaphoyiis&      \n",
      "9 shinqq          shinqqis&         shinqqiis&       \n",
      "10 soor            sooris&           sooriis&         \n",
      "11 toppay          toppayis&         toppayiis&       \n",
      "12 wolqqantt       wolqqanttis&      wolqqanttiis&    \n",
      "13 xayss           xayssis&          xayssiis&        \n",
      "14 yarkk           yarkkis&          yarkkiis&        \n",
      "15 zaway           zawayis&          zawayiis&        \n",
      "16 saaphoy         saaphoyis&        saaphoyiis&      \n",
      "17 shinqq          shinqqis&         shinqqiis&       \n",
      "18 soor            sooris&           sooriis&         \n",
      "19 toppay          toppayis&         toppayiis&       \n",
      "20 wolqqantt       wolqqanttis&      wolqqanttiis&    \n",
      "21 xayss           xayssis&          xayssiis&        \n",
      "22 yarkk           yarkkis&          yarkkiis&        \n",
      "23 zaway           zawayis&          zawayiis&        \n",
      "24 saaphoy         saaphoyis&        saaphoyiis&      \n",
      "25 shinqq          shinqqis&         shinqqiis&       \n",
      "Word Similarity Average: 0.81%\n",
      "Exact Accuracy: 0.00%\n",
      "Word in Accuracy: 93.31%\n"
     ]
    }
   ],
   "source": [
    "test_n_batches, test_batch_size = int(len(dg2.words) * 1.0 / batch_size) , 50 \n",
    "test_gen2 = dg2.gen2(batch_size=test_batch_size, n_batches=test_n_batches, trainset=False)\n",
    "total, correct = 0, 0\n",
    "in_word = 0\n",
    "sims = []\n",
    "for b in range(test_n_batches):\n",
    "    [X1, X2, X3], y = next(test_gen2)\n",
    "    for j in range(test_batch_size):\n",
    "        X33 = X3[j].reshape((1, X3.shape[1])) \n",
    "        X11 = X1[j].reshape((1, X1.shape[1], X1.shape[2], 1))\n",
    "        target = predict2(infenc, infdec, X11, X33, n_steps_out, n_features)\n",
    "        root = ''.join(dg2.one_hot_decode(X1[j]))#.replace('&', ' ')\n",
    "        word = ''.join(dg2.one_hot_decode(y[j]))#.replace('&', ' ')\n",
    "        targetS = ''.join(dg2.one_hot_decode(target))#.replace('&', ' ')\n",
    "        sims.append(dg2.word_sim(word, targetS))\n",
    "        if dg2.one_hot_decode(y[j]) == dg2.one_hot_decode(target):\n",
    "            correct += 1\n",
    "        if root.strip() in targetS.strip():\n",
    "            in_word += 1\n",
    "    print(b, root, word, targetS)\n",
    "    total += test_batch_size\n",
    "    \n",
    "word_sim_average = sum(sims)/len(sims)\n",
    "print('Word Similarity Average: {0:.2f}%'.format(word_sim_average))\n",
    "print('Exact Accuracy: %.2f%%' % (float(correct)/float(total)*100.0))\n",
    "print('Word in Accuracy: %.2f%%' % (float(in_word)/float(total)*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
